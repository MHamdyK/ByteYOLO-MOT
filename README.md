# ByteYOLOâ€‘MOT  
**Multiâ€‘ObjectÂ Tracking with YOLOv8Â +Â ByteTrack**

---

<div align="center">
  <img src="docs/demo/demo.gif" alt="Tracking demo" width="800"/>
</div>

> **ByteYOLOâ€‘MOT** is a fullyâ€‘reproducible pipeline that fineâ€‘tunes a COCOâ€‘preâ€‘trained YOLOv8 detector on the MOTâ€‘17â€¯+â€¯MOTâ€‘20 pedestrian datasets and couples it with ByteTrack for online multiâ€‘object tracking.  
> It ships with readyâ€‘toâ€‘use model weights, CLI tools for batch/realâ€‘time inference, and a Docker image for oneâ€‘command deployment.

---

## TableÂ ofÂ Contents
1. [ProjectÂ Structure](#project-structure)  
2. [QuickÂ start](#quick-start)  
3. [DatasetÂ preparation](#dataset-preparation)  
4. [TrainingÂ pipeline](#training-pipeline)  
5. [InferenceÂ pipelines](#inference-pipelines)  
6. [AugmentationsÂ &Â imageâ€‘size experiments](#augmentations--image-size-experiments)  
7. [NumPyÂ 2.0 compatibility patch](#numpy-20-compatibility-patch)  
8. [DockerÂ support](#docker-support)  
9. [ReproducingÂ the demoÂ GIF](#reproducing-the-demo-gif)  
10. [License](#license)  

---

## ProjectÂ Structure
~~~text
byteyolo-mot/
â”œâ”€â”€ data/                    # (ignored) local MOT17/MOT20 downloads
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ demo/demo.gif        # 10â€‘second illustrative GIF (â‰ˆÂ 15Â MB)
â”œâ”€â”€ models/
â”‚   â””â”€â”€ weights/
â”‚       â”œâ”€â”€ best.pt          # Fineâ€‘tuned YOLOv8m (â‰ˆÂ 100Â MB, LFS or Release)
â”‚       â””â”€â”€ README.md        # SHA256 checksum & training metadata
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ fawry_experiment.ipynb
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ cli.py
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ numpy_patch.py   # NumPyâ€‘2.0 dtype fix
â”‚   â”‚   â””â”€â”€ io.py            # Download helpers
â”‚   â””â”€â”€ pipelines/
â”‚       â”œâ”€â”€ training/
â”‚       â”‚   â”œâ”€â”€ prepare_data.py
â”‚       â”‚   â””â”€â”€ train.py
â”‚       â””â”€â”€ inference/
â”‚           â”œâ”€â”€ predict.py
â”‚           â”œâ”€â”€ track_video.py
â”‚           â””â”€â”€ submit.py
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_numpy_patch.py
â”‚   â””â”€â”€ test_inference.py
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ environment.yml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â””â”€â”€ LICENSE
~~~

> **TipÂ ðŸ”¥**Â Have a beefier GPU?Â Pass a larger `--imgsz` (e.g.Â `1536` or `1920`) to `byteyolo train`; larger inputs help detect farâ€‘away pedestrians.

---

## QuickÂ start
~~~bash
# 1Â Â·Â CloneÂ & install
git clone https://github.com/yourâ€‘org/byteyoloâ€‘mot.git
cd byteyoloâ€‘mot
pip install -r requirements.txt
pip install -e .

# 2Â Â·Â Fetch model weights & demo GIF
byteyolo fetch-assets     # downloads best.pt & demo.gif

# 3Â Â·Â Run a realâ€‘time demo on your webcam (deviceÂ 0)
byteyolo track-video --source 0 --out demo.mp4
~~~

| Command                   | Description                                                 |
|---------------------------|-------------------------------------------------------------|
| `byteyolo train`          | Fineâ€‘tune YOLOv8 on MOT17â€¯+â€¯MOT20 (â‰ˆâ€¯10â€¯h on one P100)      |
| `byteyolo predict`        | Detectionâ€‘only on images / folders                          |
| `byteyolo track-video`    | Overlay ByteTrack IDs on a video / webcam stream            |
| `byteyolo submit`         | Produce `submission.csv` for MOTâ€‘style leaderboards         |
| `byteyolo prepare`        | Convert MOT annotations to YOLO format                      |
| `byteyolo fetch-assets`   | Download model weights & demo GIF                           |

Each subâ€‘command supportsÂ `â€‘â€‘help`.

---

## DatasetÂ preparation
~~~bash
byteyolo prepare \
  --root /path/to/MOT      \   # contains mot-20/tracking & mot-17/MOT17
  --output data/yolo_data
~~~
The script:

1. Ingests **MOTâ€‘20** competition sequencesÂ `02â€¯03â€¯05` and **MOTâ€‘17** (`train`Â +Â `val`).  
2. Converts every groundâ€‘truth rectangle to YOLO format **once**.  
3. Writes
   ~~~text
   data/yolo_data/
   â”œâ”€â”€ images/{train,val}/...
   â”œâ”€â”€ labels/{train,val}/...
   â””â”€â”€ dataset.yaml
   ~~~

---

## TrainingÂ pipeline
~~~bash
byteyolo train \
  --data   data/yolo_data/dataset.yaml \
  --epochs 10 \
  --imgsz  1184 \
  --batch  10
~~~

| Hyperâ€‘param   | Value | Rationale                                       |
|---------------|-------|-------------------------------------------------|
| `epochs`      | **10**| Earlyâ€‘stops after â‰ˆâ€¯10â€¯h on KaggleÂ P100         |
| `imgsz`       | 1184  | Best mAP for farâ€‘view pedestrians               |
| `batch`       | 10    | Fits in 16â€¯GB VRAM                              |
| `optimizer`   | SGD   | More stable than AdamW for detection            |
| `lr0 / lrf`   | 0.005 / 0.015 | Backbone already warm â€“ higher LR OK |

### Augmentations
| Augmentation            | Value | Purpose                         |
|-------------------------|-------|---------------------------------|
| Horizontal flip         | 0.5   | Orientation diversity           |
| HSVÂ h/s/v jitter        | 0.015 / 0.4 / 0.2 | Colour & brightness |
| Translation             | 0.05  | Minor shifts                    |
| Scale                   | 0.2   | Zoom variance                   |
| Random erasing (CutOut) | 0.1   | Occlusion robustness            |
| RandAugment, MixUp      | *off* | Preserve object geometry for MOT|

---

## InferenceÂ pipelines

### 1Â Â·Â Detectionâ€‘only
~~~bash
byteyolo predict \
  --source imgs/ \
  --out dets/ \
  --conf 0.3 --iou 0.7
~~~

### 2Â Â·Â Video tracking
~~~bash
byteyolo track-video \
  --source input.mp4 \
  --out tracked.mp4 \
  --conf 0.3 --iou 0.7
~~~

### 3Â Â·Â MOT submission CSV
~~~bash
byteyolo submit \
  --seq /path/to/test/01 \
  --out submission.csv \
  --conf 0.3 --iou 0.7
~~~

---

## AugmentationsÂ &Â imageâ€‘size experiments

| Image size | mAP<sub>50</sub> | mAP<sub>50â€‘95</sub> |Â HOTA | Note                          |
|------------|------------------|---------------------|------|-------------------------------|
| 640        | 0.580            | 0.330              | 0.55 | Fast baseline                 |
| 832        | 0.610            | 0.360              | 0.60 |                               |
| 960        | 0.630            | 0.380              | 0.63 |                               |
| **1184**   | **0.655**        | **0.393**          | **0.65** | Bestâ€”resolves small objects |

> Bigger than 1184 (e.g.Â 1536,Â 1920) may improve recall if you have â‰¥16â€¯GB VRAMâ€”diminishing returns beyond ~2â€¯kÂ px.

---

## NumPyÂ 2.0 compatibility patch
ByteTrack still uses *bare* dtype names (`float32`, `int32`, â€¦).  
NumPyÂ â‰¥â€¯2.0 removed those aliases, raising:

